{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"colab":{"name":"convert_to_via.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"isCUzqS0RlE-"},"source":["import os\n","import re\n","import json\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns \n","\n","from glob import glob\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J2B1M1AgRlFB"},"source":["data_prefix = r'G:\\My Drive\\Tuthill Lab Shared\\Katie\\thermal_experiments\\summaries'\n","prefix = r'G:\\My Drive\\Tuthill Lab Shared\\Katie\\thermal_experiments\\data\\snow_flies'\n","data_path = os.path.join(data_prefix, 'snowfly_data.parquet.gzip')\n","data = pd.read_parquet(data_path, engine='fastparquet')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WQFimeUFRlFC"},"source":["flyids = np.unique(data.flyid)\n","cols = ['filename', 'file_size', 'file_attributes',\n","        'region_count', 'region_id',\n","        'region_shape_attributes', 'region_attributes']\n","\n","for fly in flyids:\n","    \n","    fly_data = data[data.flyid == fly]\n","    fullfile = fly_data.fullfile.iloc[0]\n","    folder, file = os.path.split(fullfile)\n","    # image_folder =  r'C:\\Users\\Rupp\\Downloads\\snapshots\\snapshots' \n","    image_folder = os.path.join(prefix, folder, 'snapshots')\n","    images = sorted(glob(os.path.join(image_folder, '*.png')))\n","    \n","    if not os.path.exists(image_folder):\n","        continue\n","    \n","    if not os.path.exists(os.path.join(prefix, folder, 'temp_data.csv')): \n","        continue\n","\n","    if not os.path.exists(os.path.join(prefix, folder, 'roi.png')): \n","        continue\n","    \n","    if os.path.exists(os.path.join(image_folder, 'via_export_csv.csv')):\n","        continue\n","    \n","    print(fly)\n","    ix = 0\n","    im = 0\n","    rows = []\n","    \n","    for im in images:\n","    # while ix < len(fly_data)-1:\n","    \n","        # image = images[im]\n","        image = im\n","        fname = os.path.basename(image)\n","        size = os.path.getsize(image)    \n","        x = int(fly_data.x_filt.iloc[ix])\n","        y = int(fly_data.y_filt.iloc[ix])\n","        shape_attr = {'name': 'point', 'cx': x, 'cy': y}\n","        region_attr = {'name': 'sf'}\n","        row = {\n","            'filename': fname,\n","            'file_size': size,\n","            'file_attributes': '{}',\n","            'region_count': 1,\n","            'region_id': 1,\n","            'region_shape_attributes': json.dumps(shape_attr),\n","            'region_attributes': json.dumps(region_attr)\n","        }\n","        rows.append(row) \n","        ix = ix + 60\n","        # im = im + 1\n","        \n","    df = pd.DataFrame(rows, columns=cols)\n","    out_fname = os.path.normpath(os.path.join(image_folder, 'via_export_csv.csv'))\n","    out_fname = out_fname.replace('\\\\', '/')\n","    df.to_csv(out_fname, index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fSAfgtCgRlFD"},"source":["## convert from via"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vN4MBpWQRlFD"},"source":["prefix = r'G:\\My Drive\\Tuthill Lab Shared\\Katie\\thermal_experiments\\data\\snow_flies';"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9LlN9MFHRlFE","outputId":"993ddebc-8020-4aa5-a2ba-0e9f886ff93c"},"source":["flyids = np.unique(data.flyid)\n","\n","for fly in flyids:\n","\n","    fly_data = data[data.flyid == fly]\n","    fullfile = fly_data.fullfile.iloc[0]\n","    folder, file = os.path.split(fullfile)\n","    \n","    pos_path = os.path.join(prefix, folder, 'temp_data.csv')\n","    corr_path = os.path.join(prefix, folder, 'snapshots', 'via_region_data.csv')\n","    outpath = os.path.join(prefix, folder, 'temp_data_corrections_visible.csv')\n","\n","    if not os.path.exists(pos_path) or not os.path.exists(corr_path):\n","        continue\n","        \n","    #if os.path.exists(outpath):\n","    #    continue\n","    \n","    print(outpath)\n","    \n","    pos = pd.read_csv(pos_path)\n","    corr = pd.read_csv(corr_path)\n","\n","    ix = 0\n","    invisible_boundary = 60\n","    rows = []\n","    cols = ['ix', 'x', 'y', 'modified', 'visible']\n","    for j in range(len(corr.region_shape_attributes)):\n","\n","        if (corr.region_count[j] > 1) and (corr.region_id[j] != 1):\n","            continue\n","\n","        row = json.loads(corr.region_shape_attributes[j])\n","        x = row['cx']\n","        y = row['cy']\n","        modified = corr.region_count[j] > 1\n","        visible = (x > invisible_boundary) | (y > invisible_boundary)\n","        new_row = {'ix': ix, 'x': x, 'y': y, 'modified': modified, 'visible': visible}\n","        rows.append(new_row)\n","        ix = ix + 60\n","\n","    df = pd.DataFrame(rows, columns=cols)\n","\n","    xs = []\n","    ys = []\n","    mods = []\n","    vis = []\n","\n","    for j in range(len(df)-1):\n"," \n","        visible = df.iloc[j].visible and df.iloc[j + 1].visible\n","        interpolate = df.iloc[j].modified and df.iloc[j + 1].modified\n","        ix = df.iloc[j].ix\n","        next_ix = df.iloc[j + 1].ix\n","\n","        if not visible:\n","            vis.extend(np.zeros(60, dtype=bool))\n","        else:\n","            vis.extend(np.ones(60, dtype=bool))\n","\n","        if interpolate:\n","            x = np.arange(ix + 1, next_ix, 1)\n","            xp = [ix, next_ix]\n","            fp_x = [df.iloc[j].x, df.iloc[j + 1].x]\n","            fp_y = [df.iloc[j].y, df.iloc[j + 1].y]\n","            xs_interp = np.interp(x, xp, fp_x)\n","            ys_interp = np.interp(x, xp, fp_y)\n","            xs.extend([fp_x[0]])\n","            xs.extend(xs_interp)\n","            ys.extend([fp_y[0]])\n","            ys.extend(ys_interp)\n","        else:\n","            xs.extend(list(pos.iloc[ix:next_ix].x_filt))\n","            ys.extend(list(pos.iloc[ix:next_ix].y_filt))\n","            mods.extend(~np.zeros(60, dtype=bool))\n","\n","    if len(xs) < len(pos):\n","        remainder = len(pos) - len(xs)\n","        visible = df.iloc[j+1].visible\n","        if not visible: \n","            vis.extend(np.zeros(remainder, dtype=bool))\n","        else:\n","            vis.extend(np.ones(remainder, dtype=bool))\n","            \n","        if df.iloc[j+1].modified:\n","            xs.extend(df.iloc[j+1].x * np.ones(remainder))\n","            ys.extend(df.iloc[j+1].y * np.ones(remainder))\n","        else:\n","            xs.extend(list(pos.iloc[next_ix:].x_filt))\n","            ys.extend(list(pos.iloc[next_ix:].y_filt))\n","\n","    new_pos = {'x_new': np.array(xs).astype(int), 'y_new': np.array(ys).astype(int), 'visible': vis}\n","    new_df = pd.DataFrame(new_pos)\n","    new_df.to_csv(outpath)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["G:\\My Drive\\Tuthill Lab Shared\\Katie\\thermal_experiments\\data\\snow_flies\\1.2.21\\SF0063\\trial1\\temp_data_corrections_visible.csv\n","G:\\My Drive\\Tuthill Lab Shared\\Katie\\thermal_experiments\\data\\snow_flies\\3.18.21\\SF0115\\trial1\\temp_data_corrections_visible.csv\n"]}]}]}